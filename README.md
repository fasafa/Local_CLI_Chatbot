# Local_CLI_Chatbot

A lightweight **local command-line chatbot** powered by a Hugging Face text generation model (e.g., `microsoft/DialoGPT-small`).  
It maintains a short-term conversational memory to create coherent multi-turn dialogue â€” all running locally with no API calls.

---

##  Features

- ğŸ’¬ **Conversational Memory** â€“ remembers the last few exchanges (configurable window)
- âš™ï¸ **Local Model Execution** â€“ runs fully offline using Hugging Face `transformers`
- ğŸ§© **Modular Structure** â€“ clean separation of logic across files
- ğŸ§  **Sliding Window Memory Buffer** â€“ keeps recent context coherent
- ğŸ–¥ï¸ **Command-Line Interface** â€“ simple, responsive, and developer-friendly

---

##  Project Structure

Local_CLI_Chatbot/
â”‚
â”œâ”€â”€ model_loader.py # Loads model & tokenizer using Hugging Face pipeline
â”œâ”€â”€ chat_memory.py # Manages short-term chat memory (sliding window)
â”œâ”€â”€ main_chat.py # Main CLI loop (integration of model + memory)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation (this file)


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create and Activate a Virtual Environment
```bash
python -m venv myenv
myenv\Scripts\activate      # On Windows

# OR
source myenv/bin/activate   # On macOS/Linux
```

2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```
## Run the Chatbot
```
python main_chat.py --model Qwen/Qwen2-0.5B --memory 4 --max-new-tokens 80
```
---

### Example Output

<img width="427" height="138" alt="Image" src="https://github.com/user-attachments/assets/6dc73c2d-6663-4b78-88b1-ef0641df06fe" />



---

 ### Command Reference

| Command       | Description                     |
| ------------- | ------------------------------- |
| `/exit`       | Quit the chatbot                |
| `/clear`      | Clear short-term chat memory    |
| (any message) | Sends your message to the model |

---


## Customization

Change model:
Edit the --model argument to try a different Hugging Face model (e.g. distilgpt2 or TinyLlama/TinyLlama-1.1B-Chat-v1.0)

Change memory window:
--memory 5 keeps the last 5 turns of conversation.

Change response length:
Adjust --max-new-tokens for longer or shorter replies.

---
ğŸ§© Author

Developed as part of a Local Chatbot Integration Task â€” demonstrating modular design, conversational memory, and local Hugging Face model usage.
